{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer detection using svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import scikitlearn in that svm ie support vector machine from that svc which is Support Vector Classification.\n",
    "from sklearn.svm import SVC\n",
    "#it is used to split the dataset into two parts one for training and one more for testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "#it is used to check the accuracy of the model \n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score, roc_curve,recall_score,precision_recall_curve, average_precision_score,accuracy_score, confusion_matrix, classification_report\n",
    "#it is used to plot the confusion matrix and calculate the classification report\n",
    "import numpy as np\n",
    "import seaborn as sns#for heatmap\n",
    "import matplotlib.pyplot as plt#for plotting\n",
    "from dask_ml.model_selection import GridSearchCV as DaskGridSearchCV#for grid search the model\n",
    "#from sklearn.feature_selection import RFECV #for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creating the dataframe for the cancer csv file\n",
    "cancer_data=pd.read_csv(\"cancer.csv\")\n",
    "#displaying the top most contents of it,to see the attribtes\n",
    "cancer_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data.shape#to check the number of rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attributes**\n",
    "ID=Shows patient id\n",
    "ClumpThickness:values can vary from 1 - 10.\n",
    "Cell Size:values can vary from 1 - 10.\n",
    "Cell Shape:values can vary from 1 - 10.\n",
    "Marginal Adhesion\t:values can vary from 1 - 10.\n",
    "Single Epithelial Cell Size:values can vary from 1 - 10.\n",
    "Bare Nuclei\t:values can vary from 1 - 10.\n",
    "Normal Nucleoli\t:values can vary from 1 - 10.\n",
    "Bland Chromatin\t:values can vary from 1 - 10.\n",
    "Mitoses\t:values can vary from 1 - 10.\n",
    "Class:values can be either 2 or 4\n",
    "2 means ben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=cancer_data[[\"ClumpThickness\",\"Cell Size\",\"Cell Shape\",\"Marginal Adhesion\",\"Single Epithelial Cell Size\",\"Bare Nuclei\",\"Normal Nucleoli\",\"Bland Chromatin\",\"Mitoses\"]]\n",
    "#drops id and class column and keeps other attributes stored in it\n",
    "df_melatonin=cancer_data.loc[cancer_data[\"Class\"]==4]\n",
    "\n",
    "df_melatonin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bengin=cancer_data.loc[cancer_data[\"Class\"]==2]\n",
    "df_bengin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visulization= cancer_data.groupby('Class').size().plot(kind='pie', autopct='%.2f', figsize=(6,6), colors=['#BC7FCD','#FB9AD1'],explode=[0.1,0.1])#pie chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the above plot we can see that majority of that present is benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the unnecessary data values and converting bare nuclei to int64 from object\n",
    "dropping=cancer_data[ (cancer_data['Bare Nuclei'] ==\"?\")].index\n",
    "cancer_data.drop(dropping , inplace=True)#stores the value same to the dataframe\n",
    "cancer_data['Bare Nuclei'].astype(str).astype(int)#conversion of object to string then to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cancer_data.drop(\"Class\", axis=1)\n",
    "X=cancer_data.drop(\"ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stores the output value\n",
    "y=cancer_data[\"Class\"]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split will split the x and y values to 4 tuples in this case we are \n",
    "#considering train size to be 80% and test size to be 20% of the data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "              'C': [0.1, 1,5, 10,15,20,100,500],  \n",
    "              'gamma': [0.5,0.80,1, 0.1], \n",
    "            'kernel': ['rbf']}#here rbf=radial basis function \n",
    "     \n",
    "modelsvc=SVC()#svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = DaskGridSearchCV(modelsvc, param_grid = parameters, cv = 5, n_jobs = -1)#cv is cross validation and n_jobs is for parallel processing of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf.fit(X_train, y_train)#fitting the model\n",
    "y_pred_rbf = svm_rbf.predict(X_test)#predicting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (svm_rbf.best_params_, svm_rbf.best_score_)\n",
    ")#printing the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)#calculating accuracy\n",
    "print(\"Accuracy:\", accuracy_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rbf = confusion_matrix(y_test, y_pred_rbf)#calculating confusion matrix\n",
    "plt.figure(figsize=(8, 6))#plotting the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)#heatmap\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "cm_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")#classification report\n",
    "print(classification_report(y_test, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**roc and auc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC (Area Under the Curve): A single metric representing the overall performance of a binary classification model based on the area under its ROC curve.\n",
    "\n",
    "ROC Curve (Receiver Operating Characteristic Curve): A graphical plot illustrating the trade-off between True Positive Rate and False Positive Rate at various classification thresholds.\n",
    "\n",
    "True Positive Rate (Sensitivity): Proportion of actual positives correctly identified by the model.\n",
    "\n",
    "False Positive Rate: The model incorrectly classifies the proportion of actual negatives as positives.\n",
    "\n",
    "Specificity (True Negative Rate): Proportion of actual negatives correctly identified by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(y_test, y_pred_rbf)#calculating auc score\n",
    "\n",
    "print(\"AUC Score on Test Data:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for polynomial kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "              'C': [0.1, 1,5, 10,15,20,100,500],  \n",
    "              'gamma': [0.5,0.80,1, 0.1], \n",
    "            'kernel': ['poly']}#here rbf=radial basis function \n",
    "     \n",
    "modelsvc=SVC()  #svm model\n",
    "\n",
    "svm_poly = DaskGridSearchCV(modelsvc, param_grid = parameters, cv = 5, n_jobs = -1)#cv is cross validation and n_jobs is for parallel processing of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly.fit(X_train, y_train)#fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (svm_poly.best_params_, svm_poly.best_score_)\n",
    ")#printing the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_poly=svm_poly.predict(X_test)#predicting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)\n",
    "print(\"Accuracy:\", accuracy_poly)#calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_poly = confusion_matrix(y_test, y_pred_poly)#calculating confusion matrix\n",
    "plt.figure(figsize=(8, 6))#plotting the confusion matrix\n",
    "sns.heatmap(cm_poly, annot=True, fmt='d', cmap='Reds', cbar=False)#heatmap\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "cm_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")#classification report\n",
    "print(classification_report(y_test, y_pred_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(y_test, y_pred_poly)#calculating auc score\n",
    "\n",
    "print(\"AUC Score on Test Data:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_linear = RFECV(SVC(kernel='linear'),cv=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "              'C': [0.1, 1,5, 10,15,20,100,500],  \n",
    "              'gamma': [0.5,0.80,1, 0.1],              'kernel': ['linear']}#here rbf=radial basis function \n",
    "modelsvc=SVC()  #svm model\n",
    "svm_linear = DaskGridSearchCV(modelsvc, param_grid = parameters, cv = 5, n_jobs = -1)#cv is cross validation and n_jobs is for parallel processing of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear.fit(X_train, y_train)#fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_linear=svm_linear.predict(X_test)#predicting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (svm_linear.best_params_, svm_linear.best_score_)\n",
    ")#printing the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm_linear.n_features_#no of features selected by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "print(\"Accuracy:\", accuracy_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_linear = confusion_matrix(y_test, y_pred_linear)#calculating confusion matrix\n",
    "plt.figure(figsize=(8, 6))#plotting the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', cbar=False)#heatmap\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "cm_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")#classification report\n",
    "print(classification_report(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(y_test, y_pred_linear)#calculating auc score\n",
    "\n",
    "print(\"AUC Score on Test Data:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={\n",
    "              'C': [0.1, 1,5, 10,15,20,100,500],  \n",
    "              'gamma': [0.5,0.80,1, 0.1], \n",
    "            'kernel': ['sigmoid']}#here rbf=radial basis function \n",
    "     \n",
    "modelsvc=SVC()  #svm model\n",
    "\n",
    "svm_sigmoid = DaskGridSearchCV(modelsvc, param_grid = parameters, cv = 5, n_jobs = -1)#cv is cross validation and n_jobs is for parallel processing of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_sigmoid.fit(X_train, y_train)#fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sigmoid=svm_sigmoid.predict(X_test)#predicting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"The best parameters are %s with a score of %0.2f\"\n",
    "    % (svm_sigmoid.best_params_, svm_sigmoid.best_score_)\n",
    ")#printing the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_sigmoid = accuracy_score(y_test, y_pred_sigmoid)\n",
    "accuracy_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sigmoid = confusion_matrix(y_test, y_pred_sigmoid)#calculating confusion matrix\n",
    "plt.figure(figsize=(8, 6))#plotting the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greys', cbar=False)#heatmap\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "cm_sigmoid#plotting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report:\")#classification report\n",
    "print(classification_report(y_test, y_pred_sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(y_test, y_pred_sigmoid)\n",
    "\n",
    "print(\"AUC Score on Test Data:\", auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
